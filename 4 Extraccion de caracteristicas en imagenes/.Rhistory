las.7.mas.importantes.chi.squared
train.filter.chi.squared <- train.original[,c("TOT_VEHICULOS_IMPLICADOS","CARRETERA","ZONA_AGRUPADA","ZONA","ACERAS","PRIORIDAD","RED_CARRETERA","TIPO_ACCIDENTE")]
test.filter.chi.squared <- test.original[,c("TOT_VEHICULOS_IMPLICADOS","CARRETERA","ZONA_AGRUPADA","ZONA","ACERAS","PRIORIDAD","RED_CARRETERA")]
summary(train.filter.chi.squared)
train.filter.chi.squared["CARRETERA"] <- NULL
test.filter.chi.squared["CARRETERA"] <- NULL
set.seed(1234)
ct6 <- ctree(TIPO_ACCIDENTE ~., train.filter.chi.squared)
testPred6 <- predict(ct6, newdata = test.filter.chi.squared)
#ct6
salida.modelo.6 <- as.matrix(testPred6)
salida.modelo.6 <- cbind(c(1:(dim(salida.modelo.6)[1])), salida.modelo.6)
colnames(salida.modelo.6) <- c("Id","Prediction")
write.table(salida.modelo.6,file="predicciones/Prediccion6.txt",sep=",",quote = F,row.names = F)
set.seed(1234)
pesos <- FSelector::information.gain(TIPO_ACCIDENTE~., train.original)
subset <- cutoff.k(pesos,7)
los.7.mas.importantes.information.gain <- as.simple.formula(subset, "TIPO_ACCIDENTE")
los.7.mas.importantes.information.gain
set.seed(1234)
pesos <- FSelector::gain.ratio(TIPO_ACCIDENTE~., train.original)
subset <- cutoff.k(pesos,7)
los.7.mas.importantes.gain.ratio <- as.simple.formula(subset, "TIPO_ACCIDENTE")
los.7.mas.importantes.gain.ratio
set.seed(1234)
pesos <- FSelector::symmetrical.uncertainty(TIPO_ACCIDENTE~., train.original)
subset <- cutoff.k(pesos,7)
los.7.mas.importantes.symmetrical.uncertainty <- as.simple.formula(subset, "TIPO_ACCIDENTE")
los.7.mas.importantes.symmetrical.uncertainty
las.7.mas.importantes.chi.squared
train.filter.entropy.bases <- train.original[,c("TOT_VEHICULOS_IMPLICADOS","ZONA_AGRUPADA","ZONA","TIPO_VIA","PRIORIDAD","RED_CARRETERA","TRAZADO_NO_INTERSEC","TIPO_ACCIDENTE")]
test.filter.entropy.bases <- test.original[,c("TOT_VEHICULOS_IMPLICADOS","ZONA_AGRUPADA","ZONA","TIPO_VIA","PRIORIDAD","RED_CARRETERA","TRAZADO_NO_INTERSEC")]
set.seed(1234)
ct7 <- ctree(TIPO_ACCIDENTE ~., train.filter.entropy.bases)
testPred7 <- predict(ct7, newdata = test.filter.entropy.bases)
#ct7
salida.modelo.7 <- as.matrix(testPred7)
salida.modelo.7 <- cbind(c(1:(dim(salida.modelo.7)[1])), salida.modelo.7)
colnames(salida.modelo.7) <- c("Id","Prediction")
write.table(salida.modelo.7,file="predicciones/Prediccion7.txt",sep=",",quote = F,row.names = F)
pesos <- FSelector::oneR(TIPO_ACCIDENTE~., train.original)
subset <- cutoff.k(pesos,7)
los.7.mas.importantes.oneR <- as.simple.formula(subset,"TIPO_ACCIDENTE")
los.7.mas.importantes.oneR
train.filter.oneR <- train.original[,c("ANIO","TOT_VEHICULOS_IMPLICADOS","ACERAS","DENSIDAD_CIRCULACION","ZONA_AGRUPADA","TOT_MUERTOS","TOT_VICTIMAS","TIPO_ACCIDENTE")]
test.filter.oneR <- test.original[,c("ANIO","TOT_VEHICULOS_IMPLICADOS","ACERAS","DENSIDAD_CIRCULACION","ZONA_AGRUPADA","TOT_MUERTOS","TOT_VICTIMAS")]
set.seed(1234)
ct8 <- ctree(TIPO_ACCIDENTE ~., train.filter.oneR)
testPred8 <- predict(ct8, newdata = test.filter.oneR)
#ct8
salida.modelo.8 <- as.matrix(testPred8)
salida.modelo.8 <- cbind(c(1:(dim(salida.modelo.8)[1])), salida.modelo.8)
colnames(salida.modelo.8) <- c("Id","Prediction")
write.table(salida.modelo.8,file="predicciones/Prediccion8.txt",sep=",",quote = F,row.names = F)
#pesos <- relief(TIPO_ACCIDENTE~., train.original, neighbours.count = 5, sample.size = 20)
#pesos
data(iris)
evaluator <- function(subset, k=5){
# genera valores aleatorios (uniforme) para cada muestra del
# conjunto de datos
splits <- runif(nrow(iris))
# tratamiento de cada una de las particiones. Para cada valor de
# particion se aplica la funcion que se define a continuacion
results <- sapply(1:k, function(i) {
# se determina el indice de las muestras para test (aproximadamente
# una fraccion 1/k de las muestras del conjunto de datos)
test.idx <- (splits >= ((i-1)/k) & (splits < (i/k)))
# todas las demas muestras seran para training
train.idx <- !test.idx
# se seleccionan las muestras en si
test <- iris[test.idx, ,drop=FALSE]
train <- iris[train.idx, , drop=FALSE]
# aprende el modelo sobre el conjunto de entrenamiento
tree <- rpart(as.simple.formula(subset,"Species"),train)
# calcula la tasa de error
error.rate <- sum(test$Species != predict(tree,test,type="c"))/nrow(test)
# devuelve la tasa de aciertos
return(1-error.rate)
})
# se muestra el subconjunto y la media de resultados y se devuelve
# la media de los resultados (un resultado por particion)
print(subset)
print(mean(results))
return(mean(results))
}
subset <- FSelector::forward.search(names(iris)[-5], evaluator)
library(rpart)
evaluator <- function(subset, k=5){
# genera valores aleatorios (uniforme) para cada muestra del
# conjunto de datos
splits <- runif(nrow(iris))
# tratamiento de cada una de las particiones. Para cada valor de
# particion se aplica la funcion que se define a continuacion
results <- sapply(1:k, function(i) {
# se determina el indice de las muestras para test (aproximadamente
# una fraccion 1/k de las muestras del conjunto de datos)
test.idx <- (splits >= ((i-1)/k) & (splits < (i/k)))
# todas las demas muestras seran para training
train.idx <- !test.idx
# se seleccionan las muestras en si
test <- iris[test.idx, ,drop=FALSE]
train <- iris[train.idx, , drop=FALSE]
# aprende el modelo sobre el conjunto de entrenamiento
tree <- rpart(as.simple.formula(subset,"Species"),train)
# calcula la tasa de error
error.rate <- sum(test$Species != predict(tree,test,type="c"))/nrow(test)
# devuelve la tasa de aciertos
return(1-error.rate)
})
# se muestra el subconjunto y la media de resultados y se devuelve
# la media de los resultados (un resultado por particion)
print(subset)
print(mean(results))
return(mean(results))
}
subset <- FSelector::forward.search(names(iris)[-5], evaluator)
f <- as.simple.formula(subset,"Species")
print(f)
copia.iris <- iris
iris <- train.original[1:200,c(8,9,10,11,30)]
evaluator <- function(subset, k=5){
# genera valores aleatorios (uniforme) para cada muestra del
# conjunto de datos
splits <- runif(nrow(iris))
# tratamiento de cada una de las particiones. Para cada valor de
# particion se aplica la funcion que se define a continuacion
results <- sapply(1:k, function(i) {
# se determina el indice de las muestras para test (aproximadamente
# una fraccion 1/k de las muestras del conjunto de datos)
test.idx <- (splits >= ((i-1)/k) & (splits < (i/k)))
# todas las demas muestras seran para training
train.idx <- !test.idx
# se seleccionan las muestras en si
test <- iris[test.idx, ,drop=FALSE]
train <- iris[train.idx, , drop=FALSE]
# aprende el modelo sobre el conjunto de entrenamiento
tree <- rpart(as.simple.formula(subset,"Species"),train)
# calcula la tasa de error
error.rate <- sum(test$Species != predict(tree,test,type="c"))/nrow(test)
# devuelve la tasa de aciertos
return(1-error.rate)
})
# se muestra el subconjunto y la media de resultados y se devuelve
# la media de los resultados (un resultado por particion)
print(subset)
print(mean(results))
return(mean(results))
}
subset <- FSelector::forward.search(names(iris)[-5], evaluator)
evaluator <- function(subset, k=5){
# genera valores aleatorios (uniforme) para cada muestra del
# conjunto de datos
splits <- runif(nrow(iris))
# tratamiento de cada una de las particiones. Para cada valor de
# particion se aplica la funcion que se define a continuacion
results <- sapply(1:k, function(i) {
# se determina el indice de las muestras para test (aproximadamente
# una fraccion 1/k de las muestras del conjunto de datos)
test.idx <- (splits >= ((i-1)/k) & (splits < (i/k)))
# todas las demas muestras seran para training
train.idx <- !test.idx
# se seleccionan las muestras en si
test <- iris[test.idx, ,drop=FALSE]
train <- iris[train.idx, , drop=FALSE]
# aprende el modelo sobre el conjunto de entrenamiento
tree <- rpart(as.simple.formula(subset,"TIPO_ACCIDENTE"),train)
# calcula la tasa de error
error.rate <- sum(test$Species != predict(tree,test,type="c"))/nrow(test)
# devuelve la tasa de aciertos
return(1-error.rate)
})
# se muestra el subconjunto y la media de resultados y se devuelve
# la media de los resultados (un resultado por particion)
print(subset)
print(mean(results))
return(mean(results))
}
subset <- FSelector::forward.search(names(iris)[-5], evaluator)
evaluator <- function(subset, k=5){
# genera valores aleatorios (uniforme) para cada muestra del
# conjunto de datos
splits <- runif(nrow(iris))
# tratamiento de cada una de las particiones. Para cada valor de
# particion se aplica la funcion que se define a continuacion
results <- sapply(1:k, function(i) {
# se determina el indice de las muestras para test (aproximadamente
# una fraccion 1/k de las muestras del conjunto de datos)
test.idx <- (splits >= ((i-1)/k) & (splits < (i/k)))
# todas las demas muestras seran para training
train.idx <- !test.idx
# se seleccionan las muestras en si
test <- iris[test.idx, ,drop=FALSE]
train <- iris[train.idx, , drop=FALSE]
# aprende el modelo sobre el conjunto de entrenamiento
tree <- rpart(as.simple.formula(subset,"TIPO_ACCIDENTE"),train)
# calcula la tasa de error
error.rate <- sum(test$Species != predict(tree,test,type="c"))/nrow(test)
# devuelve la tasa de aciertos
return(1-error.rate)
})
# se muestra el subconjunto y la media de resultados y se devuelve
# la media de los resultados (un resultado por particion)
print(subset)
print(mean(results))
return(mean(results))
}
subset <- FSelector::hill.climbing.search(names(iris)[-5], evaluator)
subset <- FSelector::cfs(TIPO_ACCIDENTE~.,train.original)
f <- as.simple.formula(subset, "TIPO_ACCIDENTE")
f
el.mejor.segun.cfs <- as.simple.formula(subset, "TIPO_ACCIDENTE")
el.mejor.segun.cfs
knitr::opts_chunk$set(echo = TRUE)
#setwd("E:/0Descargas/JDownloader/2 Mineria de datos, preprocesamiento y clasificacion")
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/2 Mineria de datos, preprocesamiento y clasificacion")
library(party)
library(FSelector)
library(mlbench)
library(ggplot2)
library(Hmisc)
library(fBasics)
library(mice)
library(outliers)
library(caret)
train.filter.relief <- train.original[,c("COMUNIDAD_AUTONOMA","PROVINCIA","MES","HORA","PRIORIDAD","ANIO","LUMINOSIDAD","TIPO_ACCIDENTE")]
test.filter.relief <- test.original[,c("COMUNIDAD_AUTONOMA","PROVINCIA","MES","HORA","PRIORIDAD","ANIO","LUMINOSIDAD")]
set.seed(1234)
ct9 <- ctree(TIPO_ACCIDENTE ~., train.filter.relief)
knitr::opts_chunk$set(echo = TRUE)
#setwd("E:/0Descargas/JDownloader/2 Mineria de datos, preprocesamiento y clasificacion")
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/2 Mineria de datos, preprocesamiento y clasificacion")
library(party)
library(FSelector)
library(mlbench)
library(ggplot2)
library(Hmisc)
library(fBasics)
library(mice)
library(outliers)
library(caret)
library(rpart)
library(pROC)
set.seed(1234)
set.seed(1234)
subset <- consistency(TIPO_ACCIDENTE~.,train.wrapper.consistency)
train.wrapper.consistency <- train.original[,c(2,3,4,5,8,11,12,17,18,19,20,21,22,23,24,26,27,28,29,30)]
test.wrapper.consistency <- test.original[,c(2,3,4,5,8,11,12,17,18,19,20,21,22,23,24,26,27,28,29)]
set.seed(1234)
set.seed(1234)
subset <- consistency(TIPO_ACCIDENTE~.,train.wrapper.consistency)
knitr::opts_chunk$set(echo = TRUE)
#setwd("E:/0Descargas/JDownloader/2 Mineria de datos, preprocesamiento y clasificacion")
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/2 Mineria de datos, preprocesamiento y clasificacion")
library(party)
library(FSelector)
library(mlbench)
library(ggplot2)
library(Hmisc)
library(fBasics)
library(mice)
library(outliers)
library(caret)
library(rpart)
library(pROC)
library(class)
rm(list=ls())
train.original <- read.csv("accidentes-kaggle.csv")
test.original <- read.csv("accidentes-kaggle-test.csv")
memory.size()
memory.limit()
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#setwd("E:/0Descargas/JDownloader/2 Mineria de datos, preprocesamiento y clasificacion")
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/2 Mineria de datos, preprocesamiento y clasificacion")
library(party)
library(FSelector)
library(mlbench)
library(ggplot2)
library(Hmisc)
library(fBasics)
library(mice)
library(outliers)
library(caret)
library(rpart)
library(pROC)
library(class)
rm(list=ls())
train.original <- read.csv("accidentes-kaggle.csv")
test.original <- read.csv("accidentes-kaggle-test.csv")
train.caret1 <- train.original[,c(7,8,9,10,11,12,30)]
train.caret1 <- train.original[,c(8,9,10,11,12,30)]
set.seed(1234)
control <- caret::trainControl(method="repeatedcv",number=10,repeats=3)
model <- caret::train(TIPO_ACCIDENTE~., data=train.caret1, method="lvq", preProcess="scale",trControl=control)
rm(list=ls())
train.original <- read.csv("accidentes-kaggle.csv")
test.original <- read.csv("accidentes-kaggle-test.csv")
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#setwd("E:/0Descargas/JDownloader/2 Mineria de datos, preprocesamiento y clasificacion")
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores/2 Mineria de datos, preprocesamiento y clasificacion")
library(party)
library(FSelector)
library(mlbench)
library(ggplot2)
library(Hmisc)
library(fBasics)
library(mice)
library(outliers)
library(caret)
library(rpart)
library(pROC)
library(class)
library(randomForest)
library(Boruta)
library(NoiseFiltersR)
library(AppliedPredictiveModeling)
library(e1071)
library(adabag)
set.seed(1234)
x = (0.96)*(1/145)
y = (0.06)*(144/145)
x+y
x/(x+y)
z=0.04*(1/145)
t = 0.94*(144/145)
z/(t+z)
(0.6*0.5)+(0.2*0.5)
0.6*0.5
0.3/0.4
bañador="puesto"
toalla="cogida"
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes")
aa <- read.csv("csvlist.csv")
View(aa)
help("read.csv")
aa <- read.csv("csvlist.csv",header = F)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes")
train.pedestrian <- read.csv("matriz_pedestrians_train.csv", header = F)
train.background <- read.csv("matriz_background_train.csv", header = F)
test.pedestrian <- read.csv("matriz_pedestrians_test.csv", header = F)
test.background <- read.csv("matriz_background_test.csv", header = F)
pedestrians_train_eti <- as.data.frame(rep(1,1916))
colnames(pedestrians_train_eti) <- c("Y")
backgorund_train_eti <- as.data.frame(rep(0,2390))
colnames(backgorund_train_eti) <- c("Y")
train.pedestrian.eti <- cbind(train.pedestrian,pedestrians_train_eti)
train.background.eti <- cbind(train.background,backgorund_train_eti)
train <- rbind(train.pedestrian.eti,train.background.eti)
set.seed(1234)
#modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
print(modelo.rf)
plot(modelo.rf)
test <- rbidn(test.pedestrian,test.background)
test <- rbind(test.pedestrian,test.background)
predic.rf <- predict(modelo.rf,newdata=test)
test.class <- as.data.frame(rep(1,500))
test.class <- cbind(test.class, as.data.frame(rep(0,600)))
test.class <- cbind(test.class, (as.data.frame(rep(0,600))))
aux <- (as.data.frame(rep(0,600)))
test.class <- cbind(test.class, aux)
test.class <- rbind(test.class, aux)
aux <- as.data.frame(rep(1,500))
aux2 <- (as.data.frame(rep(0,600)))
test.class <- rbind(aux, aux2)
test.class <- cbind(aux, aux2)
test.class <- rbind(aux, aux2)
colnames(aux) <- c("Y")
colnames(aux2) <- c("Y")
test.class <- rbind(aux, aux2)
resultado <- table(predic.rf,test.class)
test.c <- rbind(test.pedestrian,test.background)
test.c <- cbind(test.c,test.class)
resultado <- table(predic.rf,test.c$Y)
resultado
print(modelo.rf)
plot(modelo.rf)
predic.rf <- predict(modelo.rf,newdata=test)
resultado <- table(predic.rf,test.c$Y)
resultado
sumDiag <- sum(diag(resultado))
sumTotal <- sum(resultado)
fiabilidad <- sumDiag/sumTotal
ct <- ctree(Y~.,train)
library(party)
library(party)
ct <- ctree(Y~.,train)
testPred <- predict(ct, newdata = test.c)
result <- table(testPred, test.c$Y)
sumDiag <- sum(diag(result))
sumTotal <- sum(result)
fiabilidad <- sumDiag/sumTotal
rf <- randomForest(Y~.,data=train)
p <- predict(modelo.rf,test)
table(observed = test$Y, predicted = p)
p <- predict(modelo.rf,test.c)
table(observed = test.c$Y, predicted = p)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes")
train.pedestrian <- read.csv("matriz_pedestrians_train.csv", header = F)
train.background <- read.csv("matriz_background_train.csv", header = F)
test.pedestrian <- read.csv("matriz_pedestrians_test.csv", header = F)
test.background <- read.csv("matriz_background_test.csv", header = F)
pedestrians_train_eti <- as.data.frame(rep(1,1916))
colnames(pedestrians_train_eti) <- c("Y")
backgorund_train_eti <- as.data.frame(rep(0,2390))
colnames(backgorund_train_eti) <- c("Y")
train.pedestrian.eti <- cbind(train.pedestrian,pedestrians_train_eti)
train.background.eti <- cbind(train.background,backgorund_train_eti)
train <- rbind(train.pedestrian.eti,train.background.eti)
test <- rbind(test.pedestrian,test.background)
aux <- as.data.frame(rep(1,500))
colnames(aux) <- c("Y")
aux2 <- (as.data.frame(rep(0,600)))
colnames(aux2) <- c("Y")
test.aux2 <- rbind(aux, aux2)
test <- rbind(test.pedestrian,test.background)
test <- cbind(test,test.aux2)
library(party)
ct <- ctree(Y~.,train)
testPred <- predict(ct, newdata = test)
result <- table(testPred, test$Y)
sumDiag <- sum(diag(result))
sumTotal <- sum(result)
fiabilidad <- sumDiag/sumTotal
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
print(modelo.rf)
plot(modelo.rf)
predic.rf <- predict(modelo.rf,newdata=test)
resultado <- table(predic.rf,test.c$Y)
resultado <- table(predic.rf,test$Y)
resultado
sumDiag <- sum(diag(resultado))
sumTotal <- sum(resultado)
fiabilidad <- sumDiag/sumTotal
test$rightPred <- testPred == test$Y
t <- table(testPred, test$Y)
accuracy <- sum(test$rightPred)/nrow(test)
test$rightPred <- predic.rf == test$Y
t <- table(predic.rf, test$Y)
accuracy <- sum(test$rightPred)/nrow(test)
ls
ls()
rm(list=setdiff(ls(), c("train","test")))
rm(list=setdiff(ls(), c("train","test")))
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
print(modelo.rf)
plot(modelo.rf)
predic.rf <- predict(modelo.rf,newdata=test)
test$rightPred <- predic.rf == test$Y
t <- table(predic.rf, test$Y)
accuracy <- sum(test$rightPred)/nrow(test)
rm(list=setdiff(ls(), c("train","test")))
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
print(modelo.rf)
plot(modelo.rf)
predic.rf <- predict(modelo.rf,newdata=test)
test$rightPred <- predic.rf == test$Y
t <- table(predic.rf, test$Y)
accuracy <- sum(test$rightPred)/nrow(test)
head(train$Y)
class(train$Y)
train$Y <- as.factor(train$Y)
test$Y <- as.factor(test$Y)
rm(list=setdiff(ls(), c("train","test")))
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
print(modelo.rf)
plot(modelo.rf)
predic.rf <- predict(modelo.rf,newdata=test)
test$rightPred <- predic.rf == test$Y
t <- table(predic.rf, test$Y)
accuracy <- sum(test$rightPred)/nrow(test)
```{r random_forest}
rm(list=setdiff(ls(), c("train","test")))
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=50)
print(modelo.rf)
plot(modelo.rf)
predic.rf <- predict(modelo.rf,newdata=test)
test$rightPred <- predic.rf == test$Y
t <- table(predic.rf, test$Y)
accuracy <- sum(test$rightPred)/nrow(test)
accuracy
rm(list=setdiff(ls(), c("train","test")))
set.seed(1234)
modelo.rf <- randomForest::randomForest(Y~.,data = train, ntree=10)
tabla <- table(prediccion, test$Y)
prediccion <- predict(modelo.rf, newdata = test)
tabla <- table(prediccion, test$Y)
accuracy <- sum(prediccion == test$Y)/nrow(test)
accuracy <- 90.6
accuracy <- c(accuracy,accuracy)
knit_with_parameters('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes/Practica1LBP.Rmd')
knit_with_parameters('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes/Practica1LBP.Rmd')
unlink('~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes/Practica1LBP_cache', recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
setwd("~/Dropbox/zMaster/zRStudio/Master-en-Ciencia-De-Datos-e-Ingeniería-de-Computadores-3/4 Extraccion de caracteristicas en imagenes")
dataset.train <- read.csv("train_etiquetado.csv")
dataset.train <- read.csv("train_etiquetado.csv",header = T)
help("read.csv")
dataset.train <- read.csv("train_etiquetado.csv",header = F)
dataset.train <- read.csv("train_etiquetado.csv",row.names = F, col.names = F)
dataset.train <- read.csv("train_etiquetado.csv",header = F)
write.csv(train, "train_etiquetado.csv",row.names = F)
library(caret)
library(party)
